{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 3: Latent Dirichlet allocation\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** W\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* Olivier Cloux\n",
    "* Thibault Urien\n",
    "* Saskia Reiss\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 3 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given imports\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from scipy.sparse import find\n",
    "\n",
    "# Import pickle to open processed courses\n",
    "import pickle as pk\n",
    "# Use Sparks sparse vectors\n",
    "from pyspark.mllib.linalg import Vectors \n",
    "\n",
    "from utils import load_pkl, listPrettyPrint\n",
    "from lab04_helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.8: Topics extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's open the pickle to load it.\n",
    "processedCourses = load_pkl(\"cidWithBag\")\n",
    "\n",
    "# We also need the list of words\n",
    "uniqueWords = load_pkl(\"indexToWord\")\n",
    "\n",
    "# Get the course indexes for the matrix\n",
    "courseIndices = load_pkl(\"indexToCourse\")\n",
    "\n",
    "# Get the TF-IDF matrix\n",
    "TF_course_matrix = load_sparse_csr(\"TFIDF.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Transform the list of words into a spark vector usig TF-IDF\n",
    "#### Use snippets Get value with index from RDD and Spar's sparse vectors\n",
    "\n",
    "# Create an RDD we will fill with our sparse vectors \n",
    "v_dim = len(uniqueWords)\n",
    "vector_list = []\n",
    "\n",
    "# Create the sparse vectors using the matrix.\n",
    "for i in range (len(courseIndices)):\n",
    "    values = find(TF_course_matrix.getcol(i))[-1]\n",
    "    indices = (TF_course_matrix.getcol(i).nonzero())[0] # Could use first of find though\n",
    "    v = Vectors.sparse(v_dim, indices, values)\n",
    "    vector_list.append((i, v))\n",
    "    \n",
    "# In the RDD we need a tuple wit (index of document, corresponding SparseVector) then map(list)\n",
    "#docs = courseIndices.zipWithIndex(vector_list)\n",
    "#print(docs)\n",
    "\n",
    "# Create the RDD (corpus) from the list\n",
    "corpus = sc.parallelize(vector_list)\n",
    "#print(corpus.take(2))\n",
    "corpus = corpus.map(list)\n",
    "\n",
    "# Cluster the documents into ten topics using LDA\n",
    "ldaModel = LDA.train(corpus, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printTopics(model, maxTerms):\n",
    "    # Gives a list of the 10 most linked words to our topics\n",
    "    topic_indices = model.describeTopics(maxTermsPerTopic=maxTerms)\n",
    "\n",
    "    # Extraire les indices (premier tuple) de la liste de mots\n",
    "    topic = 1\n",
    "    for i in topic_indices:\n",
    "        print(\"Topic #\", topic)\n",
    "        listPrettyPrint([str(\"%s - %.7f\" % (uniqueWords[i[0][j]], i[1][j]))  for j in range(10)], 3)\n",
    "        print('\\n')\n",
    "        topic += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "printTopics(ldaModel, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Topic 1** : Materials physics\n",
    "* **Topic 2** : IC students mental health\n",
    "* **Topic 3** : Physics\n",
    "* **Topic 4** : (Risk) Management\n",
    "* **Topic 5** : Chemistry\n",
    "* **Topic 6** : Urban architecture\n",
    "* **Topic 7** : Financial Engineering\n",
    "* **Topic 8** : Circuits/Electricity (including low level as CMO)\n",
    "* **Topic 9** : Biology\n",
    "* **Topic 10** : Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : Compare to LSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.9: Dirichlet hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varying the prior on topic distribution α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_indices_list = []\n",
    "for i in range(2, 11):\n",
    "    model = (LDA.train(corpus, k=10, seed=2, docConcentration=float(i), topicConcentration=1.01))\n",
    "    topic_indices_list.append(model.describeTopics(maxTermsPerTopic=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for topic in range(1,10):\n",
    "    print(\"\\n\\t\\tTOPIC %d beta=1.01\\n\" %(topic))\n",
    "    alpha = 2\n",
    "    print\n",
    "    for i in range(0, 9):\n",
    "        print(\"\\n\\t alpha=%d \\n\" %(alpha))\n",
    "        j = topic_indices_list[i][topic-1]\n",
    "        listPrettyPrint([str(\"%s - %.7f\" % (uniqueWords[j[0][k]], j[1][k]))  for k in range(10)], 3)\n",
    "        alpha += 1\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Explain wtf is happening here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varying the prior on word distribution per topic β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_indices_list = []\n",
    "array = [1.01, 1.02, 1.03, 104, 1.05, 1.06, 1.07, 1.08, 1.09, 2.0]\n",
    "\n",
    "for i in array:\n",
    "    model = (LDA.train(corpus, k=10, seed=2, docConcentration=6.0, topicConcentration=float(i)))\n",
    "    topic_indices_list.append(model.describeTopics(maxTermsPerTopic=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for topic in range(1,10):\n",
    "    print(\"\\n\\t\\tTOPIC %d alpha=6\\n\" %(topic))\n",
    "    beta_index = 0\n",
    "    print\n",
    "    for i in range(0, 9):\n",
    "        print(\"\\n\\t beta=%d \\n\" %(array[beta_index]))\n",
    "        j = topic_indices_list[i][topic-1]\n",
    "        listPrettyPrint([str(\"%s - %.7f\" % (uniqueWords[j[0][k]], j[1][k]))  for k in range(10)], 3)\n",
    "        alpha += 1\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Explain WTF is happeing here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.10: EPFL's taught subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.11: Wikipedia structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
