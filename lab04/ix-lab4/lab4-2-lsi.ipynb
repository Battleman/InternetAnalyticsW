{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *Your group letter.*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Name 1*\n",
    "* *Name 2*\n",
    "* *Name 3*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from scipy.sparse.linalg import svds\n",
    "from lab04_helper import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15248, 854)\n"
     ]
    }
   ],
   "source": [
    "k = 300\n",
    "td_matrix = load_sparse_csr(\"occ_matrix.npz\")\n",
    "# SVD decomposition\n",
    "print(td_matrix.shape)\n",
    "u, s, v = svds(td_matrix,k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 biggest eigenvalues : \n",
      " [ 16.13695676  16.15132115  16.19533589  16.28524658  16.29884434\n",
      "  16.30850426  16.35280397  16.38506679  16.42800987  16.45750665\n",
      "  16.47148612  16.50836612  16.54994431  16.59233144  16.60731843\n",
      "  16.62798393  16.68640329  16.77242987  16.80275446  16.81623913]\n"
     ]
    }
   ],
   "source": [
    "u_k = u[:,:k]\n",
    "v_k_T = v[:k,:]\n",
    "s_k = np.diag(s[:k])\n",
    "print(\"20 biggest eigenvalues : \\n\",s[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the matrix U, each __row__ correspond to a term, and for each term the value index i correspond to how much relevant the ith concept is for this term.\n",
    "In the matrix V, each __column__ correspond to a document(cours description), and for each document the value at index i correspond to how much relevant the ith concept is for this term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************\n",
      "In topic 0 the relevant terms are:\n",
      "perspective,science,issues,participants,introduces,content,society,information,water,offers\n",
      "An the relevant courses are:\n",
      "MICRO-530,BIO-671,HUM-417(a),EE-616,MICRO-707,COM-502,ME-403,EE-490(a),MSE-463,CH-431\n",
      "*************************************************\n",
      "In topic 1 the relevant terms are:\n",
      "information,approaches,water,transport,energy,translates,focus,policy,technology,dimensioning\n",
      "An the relevant courses are:\n",
      "HUM-422(a),MSE-704,ChE-402,COM-506,FIN-608,MATH-442,EE-552,BIO-105,MGT-641(d),CH-161(en)\n",
      "*************************************************\n",
      "In topic 2 the relevant terms are:\n",
      "flexures,pneumatic,cp3,gunjan,argawal,robertson,amir,firouzeh,zhenishbek,zhakypov\n",
      "An the relevant courses are:\n",
      "ChE-301,FIN-406,EE-606,ME-466,COM-308,EE-470,EE-612,BIO-714,EE-519,BIO-802\n",
      "*************************************************\n",
      "In topic 3 the relevant terms are:\n",
      "relevant,perspective,economics,institutional,introduces,content,society,transport,technology,offers\n",
      "An the relevant courses are:\n",
      "CIVIL-351,BIO-671,MGT-466,MGT-635,EE-724,BIOENG-450,HUM-483,EE-465,PHYS-702,CIVIL-530\n",
      "*************************************************\n",
      "In topic 4 the relevant terms are:\n",
      "flexures,pneumatic,cp3,gunjan,argawal,robertson,amir,firouzeh,zhenishbek,zhakypov\n",
      "An the relevant courses are:\n",
      "ChE-403,MICRO-553,ME-415,MICRO-615,AR-301(d),ENV-400,MGT-400,EE-511,CS-487,EE-520\n",
      "*************************************************\n",
      "In topic 5 the relevant terms are:\n",
      "issues,participants,introduces,content,society,information,water,focus,technology,offers\n",
      "An the relevant courses are:\n",
      "CH-415,FIN-405,PHYS-724,CH-321,EE-533,ENV-424,EE-519,CS-341,MICRO-614,EE-704\n",
      "*************************************************\n",
      "In topic 6 the relevant terms are:\n",
      "approaches,cross-sectoral,transport,energy,sectoral,translates,basically,focus,regulation,dimensioning\n",
      "An the relevant courses are:\n",
      "EE-617,BIO-479,MICRO-452,EE-719,MGT-453,MICRO-617,BIO-441,BIO-483,MGT-469,FIN-521\n",
      "*************************************************\n",
      "In topic 7 the relevant terms are:\n",
      "issues,society,cross-sectoral,sectoral,basically,infrastructures,focus,regulation,technology,offers\n",
      "An the relevant courses are:\n",
      "EE-548,CS-322,BIOENG-513,CIVIL-457,MATH-341,ME-444,BIOENG-449,ENV-425,ME-231(a),CH-415\n",
      "*************************************************\n",
      "In topic 8 the relevant terms are:\n",
      "content,approaches,cross-sectoral,transport,energy,sectoral,translates,basically,focus,dimensioning\n",
      "An the relevant courses are:\n",
      "EE-537,MICRO-708,MSE-466,ME-453,MGT-453,CIVIL-603,FIN-503,CH-415,CH-727,FIN-525\n",
      "*************************************************\n",
      "In topic 9 the relevant terms are:\n",
      "issues,participants,content,society,approaches,transport,energy,policy,technology,offers\n",
      "An the relevant courses are:\n",
      "BIO-671,ME-453,CS-470,ChE-408,ENG-802,MSE-657,MICRO-614,EE-558,CS-322,MATH-483\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "m = 10\n",
    "wordIndex = load_pkl(\"indexToWord\")\n",
    "coursIndex = load_pkl(\"indexToCourse.txt\")\n",
    "\n",
    "n_topic_relevant_term_index = np.argpartition(u_k, n,0)[-n:]\n",
    "n_topic_relevant_document_index = np.argpartition(v_k_T, -n,1)[:,-n:]\n",
    "\n",
    "for i in range(n):\n",
    "    print(\"*************************************************\")\n",
    "    print(\"In topic\",i,\"the relevant terms are:\")\n",
    "    print(\",\".join(map(wordIndex.get,n_topic_relevant_term_index[:,i][:m])))\n",
    "    print(\"An the relevant courses are:\")\n",
    "    print(\",\".join(map(coursIndex.get,n_topic_relevant_document_index[i][:m])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-794815cd5c8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrankAtomicTerm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msearchTerm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"participants\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-794815cd5c8e>\u001b[0m in \u001b[0;36msearchTerm\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msearchTerm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrankAtomicTerm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/urien/InternetAnalyticsW/lab04/ix-lab4/lab04_helper.py\u001b[0m in \u001b[0;36mcleaner\u001b[0;34m(oneCourse)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \"\"\"\n\u001b[1;32m     64\u001b[0m     \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/stopwords.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moneCourse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mnoPunct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremovePunctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#desc without punctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0munAppended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitAppendedWords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoPunct\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#desc with split words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "wordToIndex = load_pkl(\"wordToIndex\")\n",
    "def sims(termIndex):\n",
    "    return u_k[termIndex,:] @ s_k @ v_k_T\n",
    "def rankAtomicTerm(atom):\n",
    "    index = wordToIndex.get(atom,-1)\n",
    "    print(index)\n",
    "    if(index < 0):\n",
    "        return np.zeros(td_matrix.shape[1])\n",
    "    return sims(index)\n",
    "\n",
    "\n",
    "def searchTerm(t):\n",
    "    cleaned = cleaner(t)\n",
    "    top = np.argsort(np.sum(list(map(rankAtomicTerm,cleaned)),0),0)\n",
    "    print(top)   \n",
    "searchTerm(\"participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7: Document-document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
