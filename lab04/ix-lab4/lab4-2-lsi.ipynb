{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *Your group letter.*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Name 1*\n",
    "* *Name 2*\n",
    "* *Name 3*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from scipy.sparse.linalg import svds\n",
    "from lab04_helper import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15248, 854)\n"
     ]
    }
   ],
   "source": [
    "k = 300\n",
    "td_matrix = load_sparse_csr(\"occ_matrix.npz\")\n",
    "# SVD decomposition\n",
    "print(td_matrix.shape)\n",
    "u, s, v = svds(td_matrix,k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 biggest eigenvalues : \n",
      " [ 16.13695676  16.15132115  16.19533589  16.28524658  16.29884434\n",
      "  16.30850426  16.35280397  16.38506679  16.42800987  16.45750665\n",
      "  16.47148612  16.50836612  16.54994431  16.59233144  16.60731843\n",
      "  16.62798393  16.68640329  16.77242987  16.80275446  16.81623913]\n"
     ]
    }
   ],
   "source": [
    "u_k = u[:,:k]\n",
    "v_k_T = v[:k,:]\n",
    "s_k = np.diag(s[:k])\n",
    "print(\"20 biggest eigenvalues : \\n\",s[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the matrix U, each __row__ correspond to a term, and for each term the value index i correspond to how much relevant the ith concept is for this term.\n",
    "In the matrix V, each __column__ correspond to a document(cours description), and for each document the value at index i correspond to how much relevant the ith concept is for this term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************\n",
      "In topic 0 the relevant terms are:\n",
      "flexures,pneumatic,cp3,gunjan,argawal,robertson,amir,firouzeh,zhenishbek,zhakypov\n",
      "An the relevant courses are:\n",
      "CIVIL-369,CH-447,ENV-720,MICRO-708,MSE-437,ENV-320,CH-422,ENV-546,MICRO-430,FIN-504\n",
      "*************************************************\n",
      "In topic 1 the relevant terms are:\n",
      "economics,issues,introduces,society,cross-sectoral,sectoral,basically,infrastructures,regulation,offers\n",
      "An the relevant courses are:\n",
      "ME-524,CS-487,ME-231(a),COM-308,COM-407,ENV-540,MATH-332,ENG-603,FIN-506,EE-518\n",
      "*************************************************\n",
      "In topic 2 the relevant terms are:\n",
      "flexures,pneumatic,cp3,gunjan,argawal,robertson,amir,firouzeh,zhenishbek,zhakypov\n",
      "An the relevant courses are:\n",
      "ChE-301,FIN-406,EE-606,ME-466,COM-308,EE-470,EE-612,BIO-714,EE-519,BIO-802\n",
      "*************************************************\n",
      "In topic 3 the relevant terms are:\n",
      "water,energy,sectoral,translates,basically,infrastructures,focus,regulation,policy,dimensioning\n",
      "An the relevant courses are:\n",
      "MGT-402,CS-487,ENV-425,ChE-201,CS-420,CS-470,MICRO-420,EE-552,MSE-709,MSE-464\n",
      "*************************************************\n",
      "In topic 4 the relevant terms are:\n",
      "economics,science,political,introduces,society,approaches,energy,focus,policy,dimensioning\n",
      "An the relevant courses are:\n",
      "PHYS-702,CS-622,MICRO-611,EE-612,EE-586,MGT-414,ENV-320,BIO-477,ENG-603,CS-341\n",
      "*************************************************\n",
      "In topic 5 the relevant terms are:\n",
      "issues,participants,introduces,content,society,information,water,focus,technology,offers\n",
      "An the relevant courses are:\n",
      "CH-415,FIN-405,PHYS-724,CH-321,EE-533,ENV-424,EE-519,CS-341,MICRO-614,EE-704\n",
      "*************************************************\n",
      "In topic 6 the relevant terms are:\n",
      "approaches,cross-sectoral,transport,energy,sectoral,translates,basically,focus,regulation,dimensioning\n",
      "An the relevant courses are:\n",
      "EE-617,BIO-479,MICRO-452,EE-719,MGT-453,MICRO-617,BIO-441,BIO-483,MGT-469,FIN-521\n",
      "*************************************************\n",
      "In topic 7 the relevant terms are:\n",
      "issues,society,cross-sectoral,sectoral,basically,infrastructures,focus,regulation,technology,offers\n",
      "An the relevant courses are:\n",
      "EE-548,CS-322,BIOENG-513,CIVIL-457,MATH-341,ME-444,BIOENG-449,ENV-425,ME-231(a),CH-415\n",
      "*************************************************\n",
      "In topic 8 the relevant terms are:\n",
      "issues,introduces,society,information,water,infrastructures,regulation,policy,technology,offers\n",
      "An the relevant courses are:\n",
      "EE-576,MGT-641(d),PHYS-702,ENG-400,MICRO-430,EE-617,MGT-602,MATH-442,CS-470,FIN-405\n",
      "*************************************************\n",
      "In topic 9 the relevant terms are:\n",
      "issues,participants,content,society,approaches,transport,energy,policy,technology,offers\n",
      "An the relevant courses are:\n",
      "BIO-671,ME-453,CS-470,ChE-408,ENG-802,MSE-657,MICRO-614,EE-558,CS-322,MATH-483\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "m = 10\n",
    "wordIndex = load_pkl(\"indexToWord\")\n",
    "coursIndex = load_pkl(\"indexToCourse.txt\")\n",
    "\n",
    "n_topic_relevant_term_index = np.argpartition(u_k, n,0)[-n:]\n",
    "n_topic_relevant_document_index = np.argpartition(v_k_T, -n,1)[:,-n:]\n",
    "\n",
    "for i in range(n):\n",
    "    print(\"*************************************************\")\n",
    "    print(\"In topic\",i,\"the relevant terms are:\")\n",
    "    print(\",\".join(map(wordIndex.get,n_topic_relevant_term_index[:,i][:m])))\n",
    "    print(\"An the relevant courses are:\")\n",
    "    print(\",\".join(map(coursIndex.get,n_topic_relevant_document_index[i][:m])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 course about facebook\n",
      "EE-727\n",
      "EE-593\n",
      "AR-402(w)\n",
      "ChE-302\n",
      "ME-608\n",
      "COM-308\n",
      "EE-552\n",
      "CS-714\n",
      "MGT-641(a)\n",
      "ENV-615\n",
      "Top 10 course about markov chains\n",
      "MGT-484\n",
      "MATH-332\n",
      "COM-516\n",
      "EE-605\n",
      "MGT-602\n",
      "COM-512\n",
      "FIN-606\n",
      "COM-308\n",
      "EE-477\n",
      "BIO-463\n"
     ]
    }
   ],
   "source": [
    "wordToIndex = load_pkl(\"wordToIndex\")\n",
    "\n",
    "def simVectors(querry_indices):\n",
    "    \"\"\"\n",
    "        querry_indices : List of indices of all atomic terms contained in the querry.\n",
    "        \n",
    "        Return a matrix containing for each document, \n",
    "        how much this document is similare to each atomic terms of the querry. \n",
    "        \n",
    "        If we call sim vector many times part of this can be precomputed.\n",
    "    \"\"\"\n",
    "    querry_matrix = np.zeros(u_k.shape)\n",
    "    querry_matrix[querry_indices,:]=u_k[querry_indices,:] \n",
    "    svdt = s_k @ v_k_T\n",
    "    non_normalized_sims = querry_matrix @ s_k @ v_k_T\n",
    "    \n",
    "    # Compute only the norms we care about \n",
    "    # ðŸš¨ terms_norms shape depend on querry_indices length.\n",
    "    terms_norms = np.linalg.norm(querry_matrix[querry_indices,:],axis=1)\n",
    "    weighted_document_norms = np.linalg.norm(svdt,axis=0)\n",
    "    \n",
    "    #Less computation but also avoid doing 0/0\n",
    "    term_normalized_sims = np.zeros(non_normalized_sims.shape)\n",
    "    term_normalized_sims[querry_indices,:] = (non_normalized_sims[querry_indices,:].T/terms_norms).T\n",
    "    \n",
    "    return term_normalized_sims/weighted_document_norms\n",
    "\n",
    "\n",
    "def searchTerm(t):\n",
    "    querry_words = cleaner(t)\n",
    "    querry_indices = list(filter(lambda x : x >=0,map(lambda x : wordToIndex.get(x,-1),querry_words)))\n",
    "    query_scores = np.sum(simVectors(querry_indices),0)\n",
    "    \n",
    "    return list(reversed(np.argsort(query_scores)))\n",
    "\n",
    "def printSearchResult(search_result):\n",
    "    for r in search_result:\n",
    "        print(coursIndex[r])\n",
    "#     print(\"cleaned : <\",cleaned,\">\")\n",
    "#     top = np.argsort(np.sum(list(map(rankAtomicTerm,cleaned)),0),0)\n",
    "n = 10\n",
    "t1 = \"facebook\"\n",
    "print(\"Top\",n,\"course about\",t1)\n",
    "printSearchResult(searchTerm(t1)[:n])\n",
    "t1 = \"markov chains\"\n",
    "print(\"Top\",n,\"course about\",t1)\n",
    "printSearchResult(searchTerm(t1)[:n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7: Document-document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
