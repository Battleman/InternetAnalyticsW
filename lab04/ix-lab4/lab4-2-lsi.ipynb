{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *Your group letter.*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Name 1*\n",
    "* *Name 2*\n",
    "* *Name 3*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from scipy.sparse.linalg import svds\n",
    "from lab04_helper import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 300\n",
    "td_matrix = load_sparse_csr(\"occ_matrix.npz\")\n",
    "# SVD decomposition\n",
    "print(td_matrix.shape)\n",
    "u, s, v = svds(td_matrix,k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_k = u[:,:k]\n",
    "v_k_T = v[:k,:]\n",
    "s_k = np.diag(s[:k])\n",
    "print(\"20 biggest eigenvalues : \\n\",s[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the matrix U, each __row__ correspond to a term, and for each term the value index i correspond to how much relevant the ith concept is for this term.\n",
    "In the matrix V, each __column__ correspond to a document(cours description), and for each document the value at index i correspond to how much relevant the ith concept is for this term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "m = 10\n",
    "wordIndex = load_pkl(\"indexToWord\")\n",
    "coursIndex = load_pkl(\"indexToCourse.txt\")\n",
    "\n",
    "n_topic_relevant_term_index = np.argpartition(u_k, n,0)[-n:]\n",
    "n_topic_relevant_document_index = np.argpartition(v_k_T, -n,1)[:,-n:]\n",
    "\n",
    "for i in range(n):\n",
    "    print(\"*************************************************\")\n",
    "    print(\"In topic\",i,\"the relevant terms are:\")\n",
    "    print(\",\".join(map(wordIndex.get,n_topic_relevant_term_index[:,i][:m])))\n",
    "    print(\"An the relevant courses are:\")\n",
    "    print(\",\".join(map(coursIndex.get,n_topic_relevant_document_index[i][:m])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordToIndex = load_pkl(\"wordToIndex\")\n",
    "def sims(termIndex):\n",
    "    return u_k[termIndex,:] @ s_k @ v_k_T\n",
    "def rankAtomicTerm(atom):\n",
    "    index = wordToIndex.get(atom,-1)\n",
    "    print(index)\n",
    "    if(index < 0):\n",
    "        return np.zeros(td_matrix.shape[1])\n",
    "    return sims(index)\n",
    "\n",
    "\n",
    "def searchTerm(t):\n",
    "    cleaned = cleaner(t)\n",
    "    top = np.argsort(np.sum(list(map(rankAtomicTerm,cleaned)),0),0)\n",
    "    print(top)   \n",
    "searchTerm(\"participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7: Document-document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
