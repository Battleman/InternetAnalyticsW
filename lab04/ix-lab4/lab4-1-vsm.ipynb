{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 1: Vector space models\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *W*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Cloux Olivier*\n",
    "* *Reiss Saskia*\n",
    "* *Urien Thibault*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 1 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "from scipy.sparse import csr_matrix, find\n",
    "from utils import load_json, load_pkl\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from lab04_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "courses = load_json('data/courses.txt') \n",
    "stopwords = load_pkl('data/stopwords.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pickleDump(filename, value):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pk.dump(value, f)\n",
    "        \n",
    "def listPrettyPrint(l):\n",
    "    \n",
    "    for a,b,c,d in zip(l[::4],l[1::4],l[2::4],l[3::4]):\n",
    "        print('{:<30}{:<30}{:<30}{:<}'.format(a,b,c,d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1: Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "See lab_04 helper.\n",
    "To avoid error we prefered to be able to have the preprocessing function also available for the part 2 : lsi to perfor term search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "explain why those functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creation of a dictionary that contains :\n",
    "#courses ID as keys\n",
    "#a 3-tuple(uniqueIndex, title, list[separated words]) as value\n",
    "descDict = dict() \n",
    "indexCourse = dict()\n",
    "index = 0\n",
    "for i in courses:\n",
    "    if i['courseId'] not in descDict.keys():\n",
    "        descDict[i['courseId']] = (index, i['name'], cleaner(i))\n",
    "        indexCourse[index] = i['courseId']\n",
    "        index += 1\n",
    "\n",
    "pickleDump(r\"cidWithBag.txt\", descDict)\n",
    "pickleDump(r\"indexToCourse.txt\", indexCourse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words for Internet Analytics course are (in alphabetical order) :\n",
      "acquired                      activities                    ad                            ad\n",
      "advertisement                 algebra                       algebra                       algorithms\n",
      "algorithms                    analysis                      analytics                     analytics\n",
      "analyze                       apache                        applications                  applications\n",
      "assessment                    auctions                      auctions                      balance\n",
      "based                         based                         basic                         basic\n",
      "basic                         cathedra                      chains                        class\n",
      "class                         class                         cloud                         clustering\n",
      "clustering                    collection                    com-3                         combination\n",
      "communication                 community                     community                     computing\n",
      "computing                     concepts                      concepts                      concrete\n",
      "content                       courses                       courses                       coverage\n",
      "curated                       current                       data                          data\n",
      "data                          data                          data                          data\n",
      "datasets                      datasets                      decade                        dedicated\n",
      "designed                      detection                     detection                     develop\n",
      "dimensionality                draw                          e-commerce                    e-commerce\n",
      "effectiveness                 efficiency                    end                           exam\n",
      "expected                      explore                       explore                       explore\n",
      "explore                       explores                      fields                        final\n",
      "foundational                  frameworks                    functions                     fundamental\n",
      "good                          graph                         graphs                        hadoop\n",
      "hadoop                        hands-on                      homeworks                     homeworks\n",
      "important                     information                   information                   infrastructure\n",
      "inspired                      internet                      internet                      java\n",
      "key                           keywords                      knowledge                     lab\n",
      "laboratory                    labs                          labs                          large-scale\n",
      "large-scale                   large-scale                   learning                      learning\n",
      "learning                      learning                      lectures                      lectures\n",
      "linear                        linear                        machine                       machine\n",
      "main                          map-reduce                    markov                        material\n",
      "materials                     media                         methods                       methods\n",
      "midterm                       mining                        mining                        mining\n",
      "modeling                      models                        models                        models\n",
      "models                        models                        modelsdata-mining             networking\n",
      "networking                    networking                    networks                      number\n",
      "number                        online                        online                        online\n",
      "online                        online                        outcomes                      past\n",
      "practical                     practice                      prerequisites                 problems\n",
      "problems                      project                       provide                       questions\n",
      "real                          real-world                    real-world                    real-world\n",
      "real-world                    recommended                   recommender                   recommender\n",
      "reduction                     related                       required                      retrieval\n",
      "retrieval                     search                        search                        seeks\n",
      "self-contained                services                      services                      services\n",
      "services                      services                      sessions                      sessions\n",
      "social                        social                        social                        social\n",
      "social                        spark                         specifically                  start\n",
      "statistics                    stochastic                    stream                        stream\n",
      "structures                    student                       student                       systems\n",
      "systems                       teaching                      techniques                    theoretical\n",
      "theory                        topic                         topic                         typical\n",
      "ubiquitous                    user                          weekly                        work\n"
     ]
    }
   ],
   "source": [
    "ixWords = sorted(descDict['COM-308'][2])\n",
    "print(\"Words for Internet Analytics course are (in alphabetical order) :\")\n",
    "listPrettyPrint(ixWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creation of 2 dictionary.\n",
    "#wordIndex contains all distinct words as keys and their unique index as value\n",
    "#indexWord is the exact opposite. \n",
    "wordIndex = dict() \n",
    "index = 0\n",
    "for i in descDict:\n",
    "    for word in descDict[i][2]:\n",
    "        if word not in wordIndex.keys():\n",
    "            wordIndex[word] = index\n",
    "            index += 1;\n",
    "\n",
    "indexWord = dict((v, k) for k, v in wordIndex.items())\n",
    "assert(len(indexWord) == len(wordIndex))\n",
    "pickleDump(\"indexToWord\", indexWord)\n",
    "pickleDump(\"wordToIndex\", wordIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creation of sparse occurence matrix. we define values in occValues and its indices in occRow and occCol. \n",
    "#If two pairs of indices are identical, their values will be added. \n",
    "occValues = []\n",
    "occRow = [] #indices of words\n",
    "occCol = [] #indices of courses\n",
    "\n",
    "i = 0\n",
    "for cid in descDict: #iterate through all courses (and their bag of words)\n",
    "    cIndex = descDict[cid][0] #get column for this course\n",
    "    for word in descDict[cid][2]: #then append to correct list :\n",
    "        occCol.append(cIndex) #the col index\n",
    "        occRow.append(wordIndex[word]) #row index\n",
    "        occValues.append(1) #value (1, as each word represents 1 occurence)\n",
    "\n",
    "occurenceMatrix = csr_matrix((occValues, (occRow, occCol)), shape=((len(wordIndex), len(descDict))), dtype=np.float64)\n",
    "save_sparse_csr(\"occ_matrix\", occurenceMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creation of TF, IDF and TFIDF matrices\n",
    "mostFreqWord = occurenceMatrix.max(axis=0).data #create list of max occurence for each course\n",
    "\n",
    "#by definition : TF is term freq divided by freq of most freq word in the same document\n",
    "TF = csr_matrix(occurenceMatrix/mostFreqWord)\n",
    "IDF = csr_matrix(-np.log2((occurenceMatrix != 0).sum(1)/len(descDict)))\n",
    "\n",
    "TFIDF = TF.multiply(IDF)\n",
    "np.save(\"TFIDF\", TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with greatest scores are :\n",
      "services                      online                        real-world                    social\n",
      "mining                        explore                       networking                    e-commerce\n",
      "hadoop                        large-scale                   recommender                   ad\n"
     ]
    }
   ],
   "source": [
    "ixIndex = descDict['COM-308'][0]\n",
    "tmp = TFIDF.getcol(ixIndex)\n",
    "ixBigIndices = (np.argsort(tmp.todense(), axis=0)[-15:])\n",
    "\n",
    "\n",
    "ixBigScores = []\n",
    "for i in ixBigIndices:\n",
    "    ixBigScores.append(indexWord[int(i)])\n",
    "ixBigScores.reverse()\n",
    "print(\"Words with greatest scores are :\")\n",
    "listPrettyPrint(ixBigScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "The difference between high and big scores is the essence of TF-IDF : high scores indicate the term is very frequent in the document but appears in few documents, when a low score shows the word is rare in the document (appears only once or twice), but most documents have this word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3: Document similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
