{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 1: Vector space models\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *W*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Cloux Olivier*\n",
    "* *Reiss Saskia*\n",
    "* *Urien Thibault*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 1 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "from utils import load_json, load_pkl\n",
    "import re\n",
    "\n",
    "from porter_stemming import PorterStemmer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmer.stem(\"Oscillators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "courses = load_json('data/courses.txt')\n",
    "stopwords = load_pkl('data/stopwords.pkl')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1: Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def removeStopWords(listWords):\n",
    "    \"\"\"remove stopwords from a text (list of strings)\n",
    "    \"\"\"\n",
    "    return list(filter(lambda x : len(x)>0 and x not in stopwords, listWords))\n",
    "\n",
    "def toWordList(description):\n",
    "    \"\"\"\n",
    "    Removes punctuation and splits appended words (because of missing \\\\n) and \n",
    "    puts all words in lowercase. Returns a list of cleaned words. \n",
    "    \n",
    "    Keyword arguments:\n",
    "    description -- A unique, long string\n",
    "    \"\"\"\n",
    "    punct = \",.\\n\\t:;0'%#/()[]\\xa0\"\n",
    "    puncttrans = str.maketrans(punct,\" \"*len(punct))\n",
    "    patternAppended = re.compile(\"([a-z][a-z])([A-Z])([a-z][a-z])\")\n",
    "    patternDash = re.compile(\"\\ +-\\ *|\\ *-\\ +\")\n",
    "    unDashed = patternDash.sub(\"\", description)\n",
    "    return patternAppended.sub(\"\\\\1 \\\\2\\\\3\", unDashed).lower().translate(puncttrans).split(\" \")\n",
    "\n",
    "def takeOutNumbers(listWords):\n",
    "    \"\"\"\n",
    "    Removes all numbers that are alone or a only seperated by h.\n",
    "    Permits to keep words that exist with a number (ex: 3SAT)\n",
    "    \"\"\"\n",
    "#     pattern = re.compile(r\"^\\d+(?:h\\d*)?[^\\w]\") #\"(\\d+)|((\\d)+h(\\d)+)\"\n",
    "    pattern = re.compile(r\"\\d{1,2}h\\d{1,2}\")\n",
    "#     return [pattern.sub(\"BLABLABLABLA\", i) for i in listWords]\n",
    "    noHours = [pattern.sub(\"\", i) for i in listWords]\n",
    "    return list(filter(lambda x : not x.isdecimal(), noHours))\n",
    "\n",
    "# def splitAppendedWords():\n",
    "    \n",
    "# def veryFrequent():\n",
    "    \n",
    "# def inFrequent():\n",
    "    \n",
    "# def stemming():\n",
    "\n",
    "# def lemmatise():\n",
    "    \n",
    "# def ngram():\n",
    "\n",
    "# def blackMagic():\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example = courses[0]['description']\n",
    "# print(example)\n",
    "def cleaner(oneCourse):\n",
    "    description = oneCourse['description']\n",
    "    return removeStopWords(takeOutNumbers(toWordList(description)))\n",
    "\n",
    "cleaned = [cleaner(i) for i in courses]\n",
    "\n",
    "[print(\"\\n\".join(i)) for i in cleaned[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# desc = courses[0]['description']\n",
    "# punct = \",.\\n\\t-:0'\\xa0\"\n",
    "# puncttrans = str.maketrans(punct,\" \"*len(punct))\n",
    "# pattern = re.compile(\"([a-z][a-z])([A-Z])([a-z][a-z])\")\n",
    "# x = pattern.sub(\"\\\\1 \\\\2\\\\3\", desc).lower().translate(puncttrans).split(\" \")\n",
    "# x = list(filter(lambda x : len(x)>0 and x not in stopwords, x))\n",
    "\n",
    "# print(\"\\n\".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3: Document similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
