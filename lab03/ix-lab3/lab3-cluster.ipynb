{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 — clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given Imports\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "from operator import itemgetter\n",
    "\n",
    "# Import panda that is easier to use than dicts\n",
    "import pandas as pd\n",
    "# Import random\n",
    "import random as rn\n",
    "\n",
    "# Import bokeh\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.models import HoverTool, ResetTool, PanTool, WheelZoomTool, SaveTool\n",
    "output_notebook()\n",
    "# Categorial colors\n",
    "from bokeh.palettes import Dark2_8\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.11 : Clustering tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's open the pickle to load it.\n",
    "with open( \"tagCoord.pickle\", \"rb\" ) as f:\n",
    "    tagEmbed = pk.load( f, encoding=\"utf-8\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cluster the data using the k-means clustering algorithm.\n",
    "\n",
    "# Input: N data points {x1, ..., xn} , given in our pickle.\n",
    "#        K number of clusters, between 2 and 5 for us.\n",
    "# Output: We will have mu_k, center of clusters, K times.\n",
    "#         r_nk, point-cluster assigment indicator. If r_nk = 1, n is in cluster k.\n",
    "\n",
    "# r_nk = 1 only for k = argmin ||xn - mu_k||\n",
    "# mu_k = sum_over_n(r_nk + xn)/sum_over_n(r_nk)\n",
    "def k_mean(k, data, give_up = 1000):\n",
    "    mat = np.array(list(zip(*data))[1])\n",
    "    print(mat.shape)\n",
    "    #We arbitrary decide that if the centroids all move less than 1e-5 * the variance, they have converged and we can stop.\n",
    "    var = np.var(mat,1)\n",
    "    thershold = np.linalg.norm(var)*1e-5\n",
    "    \n",
    "    #Pick k random data points as initialposition for centroids.\n",
    "    centroids_idx = np.random.randint(mat.shape[0], size=k)\n",
    "    centroids = mat[centroids_idx]\n",
    "    \n",
    "    distances = np.zeros((mat.shape[0],k))\n",
    "    \n",
    "    # We should loop until convergence but just in case we don't, we set a maximal number of steps.\n",
    "    for step in range(0,give_up):\n",
    "        \n",
    "        #For each centroid, the distance between each point and this centroids.\n",
    "        for i in range(0, k):\n",
    "            distances[:,i] = np.linalg.norm(mat - centroids[i,:],axis=1)\n",
    "        \n",
    "        #The index of the closet centroids for each point\n",
    "        closest = np.argpartition(distances,1,1)[:,0]\n",
    "        \n",
    "        #For each centroid, the center of gravity of all point closest to this centroid. \n",
    "        means = np.zeros(centroids.shape)\n",
    "        for i in range(0, k):\n",
    "            means[i,:] = np.mean(mat[closest == i,:],0)\n",
    "            \n",
    "        #We will set the new centroids as the center of gravity of the cluster we found.\n",
    "        #But first we compute the distance between the current position of each centroid and its position for the next step.\n",
    "        move = means - centroids\n",
    "        dist = np.max(np.linalg.norm(move,axis=0))\n",
    "        \n",
    "        #If no centroid have moved more than the thershold, we are close enough from the convergence point.\n",
    "        if(dist < thershold):\n",
    "            return closest\n",
    "        centroids = means\n",
    "    print(\"Centroids have not stabilized after\",give_up,\"steps\")\n",
    "    return closest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = list(tagEmbed.items())\n",
    "# Start with K = 2\n",
    "clustering = k_mean(2,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We project on choosen directions. Here 0 is \"good-bad\". See the categories in dimred.\n",
    "main_dims = (0,1)\n",
    "\n",
    "# Use the categorial colors for clustering.\n",
    "source = ColumnDataSource(\n",
    "    data={\n",
    "        \"x\": [x[1][main_dims[0]] for x in data],\n",
    "        \"y\": [x[1][main_dims[1]] for x in data],\n",
    "        \"name\": [x[0] for x in data],\n",
    "        \"color\": [Dark2_8[x] for x in clustering],\n",
    "    })\n",
    "\n",
    "hover = HoverTool(\n",
    "    tooltips=[\n",
    "        (\"Name\", \"@name\"),\n",
    "    ])\n",
    "tools = [hover, ResetTool(), PanTool(), WheelZoomTool(), SaveTool()]\n",
    "p = figure(plot_width=960, plot_height=360, tools=tools, title=\"Mouse over the dots\")\n",
    "p.circle(\"x\", \"y\", source=source, size=20, color=\"color\", alpha=0.5)\n",
    "show(p, notebook_handle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.12 : Clustering movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Frame of all movies and genres. Taken directly from the introduction in dimred.\n",
    "data_movies = sc.textFile(\"/ix/ml-20m/movies.txt\").map(json.loads)\n",
    "\n",
    "# Frame of genres in movie order.\n",
    "intermediateGenresDF = pd.DataFrame(data_movies.map(itemgetter(\"genres\")).collect())\n",
    "# Frame of all unique genres. There are 20 genres, including \"No genre listed\", once we drop None.\n",
    "genresDF = pd.DataFrame(pd.DataFrame(intermediateGenresDF.values.flatten()).drop_duplicates().reset_index()[0])\n",
    "# We drop \"None\", as it is to disregard.\n",
    "genresDF = pd.DataFrame(genresDF[~genresDF[0].isnull()].reset_index()[0])\n",
    "\n",
    "# We need anothe dataframe that lists all the genre lsits with the right movieId as they are NOT continuous\n",
    "genresListsDF = pd.DataFrame(data_movies.map(itemgetter(\"genres\", \"movieId\")).collect(),columns=[\"genres\", \"movieId\"])\n",
    "\n",
    "# Let's open the pickle wewant to cluster.\n",
    "# The file is in the shape of a list of tuples, in form of: (Id, Movie name)\n",
    "with open( \"most-rated.pickle\", \"rb\" ) as f:\n",
    "    ratedMovies = pk.load( f, encoding=\"utf-8\" )\n",
    "# Put it in a DF for easier use.\n",
    "ratedMoviesDF = pd.DataFrame(list(ratedMovies), columns=['movieId', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining the Jaccard distance for our exercice.\n",
    "# x1 is a matrix, x2 is a vector. Returns a matrix.       \n",
    "def jaccard(x1, x2):\n",
    "    # Gives intersection directly\n",
    "    set1 = x1 @ x2\n",
    "    # Gives union\n",
    "    set2 = (x1 + x2).clip(max=1)\n",
    "    return 1 - ( set1 / np.sum(set2) )\n",
    "\n",
    "# The k-medioids algorithm implementation. \n",
    "def kmedAlgo(k, mat, give_up = 1000):\n",
    "    # Same as before.\n",
    "    # We arbitrary decide that if the medioids all move less than 1e-5 * the variance, they have converged and we can stop.\n",
    "    var = np.var(mat,1)\n",
    "    thershold = np.linalg.norm(var)*1e-5\n",
    "    \n",
    "    #Pick k random data points as initial position for medioids.\n",
    "    medioids_idx = np.random.randint(mat.shape[0], size=k)\n",
    "    medioids = mat[medioids_idx]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # We should loop until convergence but just in case we don't, we set a maximal number of steps.\n",
    "    for step in range(0, give_up):\n",
    "        \n",
    "        distances = np.zeros((mat.shape[0],k))\n",
    "        #For each medioid, the distance between each point and this medioids.\n",
    "        for i in range(0, k):\n",
    "            distances[:,i] = jaccard(mat, medioids[i,:])\n",
    "        #The index of the closet medioid for each point\n",
    "        closest = np.argpartition(distances,1,1)[:,0]\n",
    "        \n",
    "        new_medioids = np.zeros(medioids.shape)\n",
    "        #For each cluster\n",
    "        for i in range(0, k):\n",
    "            #Matrix of all points in cluster i \n",
    "            clusteri = mat[closest == i,:]\n",
    "            #As we loose the index in mat, we use another matrix with the index of each point\n",
    "            real_index = np.argwhere(closest == i)\n",
    "            #List of all Jaccard distance\n",
    "            distSum = list()\n",
    "            for pt in clusteri:\n",
    "                distSum = distSum + [list(jaccard(clusteri, pt))]\n",
    "            miIndex = real_index[distSum.index(min(distSum))]\n",
    "            new_medioids[i] = mat[miIndex]\n",
    "\n",
    "        #We will set the new medioids as the center of gravity of the cluster we found.\n",
    "        #But first we compute the distance between the current position of each medioids and its position for the next step.\n",
    "        move = new_medioids - medioids\n",
    "        dist = np.max(np.linalg.norm(move,axis=0))\n",
    "        \n",
    "        #If no centroid have moved more than the thershold, we are close enough from the convergence point.\n",
    "        if(dist < thershold):\n",
    "            return closest\n",
    "        medioids = new_medioids\n",
    "    print(\"Medioids have not stabilized after\",give_up,\"steps\")\n",
    "    return closest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the matrix with 0's\n",
    "matKmed = np.zeros((ratedMoviesDF.shape[0],genresDF.shape[0]))\n",
    "\n",
    "# Fill the matrix with the data. We use what we did in the dimred exercise again.\n",
    "\n",
    "# Create an index of id's for ratedMoviesDF.\n",
    "ratedMoviesIndex = pd.Index(ratedMoviesDF.movieId)\n",
    "\n",
    "# Fill the matrix by iterating over all the ids in ratedMovies\n",
    "# For each id, seek it's genres and fill the matrix with 1 if the genr eis lsited, 0 if it isn't\n",
    "# \"None\" in genresListsDF is disregarded.\n",
    "a = 0\n",
    "for mId in ratedMoviesIndex:\n",
    "    # Exract the right list of genres\n",
    "    movieGenres = (genresListsDF[genresListsDF.movieId == mId].genres).tolist()[0]\n",
    "    # Drop the Null\n",
    "    #movieGenres = movieGenres[~movieGenres.isnull()]\n",
    "    # Put a 1 in the matrix a the right place\n",
    "    genreId = np.array(list(genresDF.isin(movieGenres)[0]))\n",
    "    \n",
    "    #We put a 1 if the genre is present in the lsit for that id.\n",
    "    matKmed[a, :] = genreId\n",
    "    a += 1\n",
    "\n",
    "# Call method to cluster.\n",
    "k = 2\n",
    "clusterKmed = kmedAlgo(k,matKmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "per_genre_total =  np.sum(matKmed,0)\n",
    "for i in range(0,k):\n",
    "    # Visualize the frequency of each film genre in a cluster\n",
    "    bars = np.sum(matKmed[clusterKmed == i, :],0)/per_genre_total *100\n",
    "    \n",
    "    x = range(genresDF.shape[0])\n",
    "    f = plt.figure()\n",
    "    ax = f.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    ax.bar(x,height=bars)\n",
    "    \n",
    "    plt.ylabel(\"Film % of type x\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(genresDF[0].tolist(),{\"rotation\":90})\n",
    "    f.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, and as expected, the frequency of a genre in one cluster is complementary to the frequency in the other cluster.\n",
    "\n",
    "We can also interpret the clusters using which genres are dominant. In the first cluster, we have mostly action and non-realistic categories (with the exception of “Documentary”). The second cluster has mostly realistic categories, like “Mystery” or “Thriller”.\n",
    "\n",
    "We could also say that the first cluster is more \"for children\", aving less violent genres, and the second cluster is \"for adults\" with things like horror and mysteries. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
