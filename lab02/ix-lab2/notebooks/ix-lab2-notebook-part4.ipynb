{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks: structure, evolution & processes\n",
    "**Internet Analytics - Lab 2**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** W\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* Olivier Cloux\n",
    "* Thibault Urien\n",
    "* Saskia Reiss\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 4 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 PageRank\n",
    "\n",
    "### 2.4.1 Random Surfer Model\n",
    "\n",
    "#### Exercise 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#necessary imports\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random as random\n",
    "import csv\n",
    "\n",
    "#global variables\n",
    "jumps = 1000\n",
    "dangling_fac = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load graphs\n",
    "G1=nx.read_adjlist('../data/components.graph', create_using=nx.DiGraph(), nodetype=int)\n",
    "G2=nx.read_adjlist('../data/absorbing.graph', create_using=nx.DiGraph(), nodetype=int)\n",
    "Gwiki=nx.read_adjlist('../data/wikipedia.graph', create_using=nx.DiGraph(), nodetype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#helper functions, to make code cleaner\n",
    "def print_dict_sorted(d, precision):\n",
    "    \"\"\"print a dictionnary sorted by it's keys\n",
    "    argument 'precision': gives number of desired leading zeros\n",
    "    \"\"\"\n",
    "    print(\"Weight of each node :\")\n",
    "    for k, v in sorted(d.items()): \n",
    "        print(\"Node\",str(k).zfill(precision),\"has score\", v)\n",
    "\n",
    "#Surfer\n",
    "def surfer(G, jumps):\n",
    "    \"\"\"Surfs through an networkX graph\"\"\"\n",
    "    nodes_list = G.nodes()\n",
    "    nodes_and_weight = dict(zip(G.nodes(), [0]*G.number_of_nodes()))\n",
    "    seed = random.sample(nodes_list, 1).pop()\n",
    "    current = seed\n",
    "    i = 0\n",
    "    while i < jumps:\n",
    "        \n",
    "        i+= 1\n",
    "        nodes_and_weight[current] += 1\n",
    "        possible_nodes = G.edges(current)\n",
    "        if len(possible_nodes) >= 1: #check for dead end\n",
    "            current = random.sample(possible_nodes,1).pop()[1]\n",
    "        else:\n",
    "            print(\"Reached a dead end after\",i,\"jumps and\",i+1,\"visited pages. No links in this page\")\n",
    "            break\n",
    "    \n",
    "    #return normalized version\n",
    "    nodes_and_weight.update((k, v/i) for k,v in nodes_and_weight.items())\n",
    "    return nodes_and_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of components graph\n",
    "We see below that not all components are connected (the network is not one giant component). Thus, entering at one node traps us in the connected component and excludes us from different component(s). This behaviour is to be avoided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "surf1 = surfer(G1, jumps)\n",
    "print_dict_sorted(surf1, 1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of absorbing graph\n",
    "The result here is better seen when launching the code multiple times.\n",
    "We quickly see there is a dangling node (node with no outgoing edges). This denotes an absorbing behaviour, meaning once this node is reached we can't keep crawling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "surf2 = surfer(G2, jumps)\n",
    "print_dict_sorted(surf2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modified_surfer(G, jumps, dang_fac):\n",
    "    \"\"\"Surfs through an networkX graph\"\"\"\n",
    "    nodes_list = G.nodes()\n",
    "    nodes_and_weight = dict(zip(G.nodes(), [0]*G.number_of_nodes())) #creates dict of node ID and it's score (0)\n",
    "    seed = random.sample(nodes_list, 1).pop()\n",
    "    current = seed\n",
    "    i = 0\n",
    "    while i < jumps:\n",
    "        \n",
    "        nodes_and_weight[current] += 1\n",
    "        possible_nodes = G.edges(current)\n",
    "        if len(possible_nodes) == 0 or random.randrange(0, 1) < dang_fac: \n",
    "            current = random.sample(nodes_list, 1).pop() #take one node at random\n",
    "        else:\n",
    "            current = random.sample(possible_nodes,1).pop()[1] #pick one in linked nodes\n",
    "        i += 1\n",
    "        \n",
    "    #return normalized version\n",
    "    nodes_and_weight.update((k, v/i) for k,v in nodes_and_weight.items())\n",
    "    return nodes_and_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of components graph with modified surfer\n",
    "The below result seems much better, as we now visited all components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "surf1 = modified_surfer(G1, jumps, dangling_fac)\n",
    "print_dict_sorted(surf1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of absorbing graph with modified surfer\n",
    "Our surfer does not halt anymore when reaching a dangling node, which is the correct behaviour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "surf2 = modified_surfer(G2, jumps, dangling_fac)\n",
    "print_dict_sorted(surf2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.2 Power Iteration Method\n",
    "\n",
    "#### Exercise 2.14: Power Iteration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "theta = 0.85\n",
    "\n",
    "def google_matrix(graph):\n",
    "    #Compute the google matrix for the given graph\n",
    "    N = graph.number_of_nodes()\n",
    "    w = np.zeros(N) #dangling indicator\n",
    "    H = np.zeros((N, N))\n",
    "\n",
    "    for node in graph.nodes(): #analyse every node iteratively\n",
    "        edges = (graph.edges(node)) #type : edges = list of connected nodes\n",
    "        if(len(edges) == 0): #no outgoing egde <-> dangling node\n",
    "            w[node] = 1\n",
    "        else :\n",
    "            edges_indices = np.array([x[1] for x in edges], dtype=int)  \n",
    "            H[node][edges_indices] = 1/len(edges)\n",
    "    H2 = H + ((w) * np.ones((N,1)).T)/N\n",
    "    G = theta*H2 + (1-theta)*np.ones((N, N))/N\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = google_matrix(Gwiki)\n",
    "N = Gwiki.number_of_nodes()\n",
    "pivec = np.ones(N)/N #original pi\n",
    "for i in range(5000): #long operation, decrease for faster result\n",
    "    pivec = pivec @ G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/wikipedia_titles.tsv', newline='\\n') as datafile:\n",
    "    fin = datafile.read().splitlines(True)[1:]\n",
    "    reader = csv.reader(fin, delimiter='\\t')\n",
    "dictionnary = dict((int(row[0]), row[1]) for row in reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desired_max = 10\n",
    "# np.argpartition is an efficient way to get top N values but returns them unsorted.\n",
    "max_indices = np.argpartition(pivec, -desired_max)[-desired_max:]\n",
    "value_to_index = map(lambda x : (pivec[x], x), max_indices)\n",
    "#Sort only the top N values.\n",
    "sorted_indices = sorted(value_to_index, key= lambda x:x[0], reverse=True)\n",
    "\n",
    "print(\"The\",desired_max,\"max elements are :\")\n",
    "j = 1\n",
    "for i in sorted_indices:    \n",
    "    print(\"#\",j,\":\",dictionnary[i[1]],\"with score\",i[0])\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.3 Gaming the system *(Bonus)*\n",
    "\n",
    "#### Exercise 2.15 *(Bonus)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_history = list(dictionnary.keys())[list(dictionnary.values()).index('History of mathematics')]\n",
    "desired_max = 300\n",
    "max_indices = np.argpartition(pivec, -desired_max)[-desired_max:]\n",
    "#The new links between the top N page and the page we try to boost.\n",
    "mapped = zip(max_indices, [id_history]*desired_max)\n",
    "print(pivec[id_history])\n",
    "Gwiki2 = nx.read_adjlist('../data/wikipedia.graph', create_using=nx.DiGraph(), nodetype=int)\n",
    "\n",
    "Gwiki2.add_edges_from(mapped)\n",
    "\n",
    "G2 = google_matrix(Gwiki2)\n",
    "pivec2 = np.ones(N)/N #original pi\n",
    "for i in range(5000): #long operation, decrease for faster result\n",
    "    pivec2 = pivec2 @ G2\n",
    "    \n",
    "print(pivec2[id_history])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
