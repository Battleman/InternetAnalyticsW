{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks: structure, evolution & processes\n",
    "**Internet Analytics - Lab 2**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** W\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* Olivier Cloux\n",
    "* Thibault Urien\n",
    "* Saskia Reiss\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 4 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 PageRank\n",
    "\n",
    "### 2.4.1 Random Surfer Model\n",
    "\n",
    "#### Exercise 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#necessary imports\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "\n",
    "#global variables\n",
    "jumps = 100\n",
    "dangling_fac = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load graphs\n",
    "G1=nx.read_adjlist('../data/components.graph', create_using=nx.DiGraph(), nodetype=int)\n",
    "G2=nx.read_adjlist('../data/absorbing.graph', create_using=nx.DiGraph(), nodetype=int)\n",
    "Gwiki=nx.read_adjlist('../data/wikipedia.graph', create_using=nx.DiGraph(), nodetype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#helper functions, to make code cleaner\n",
    "def print_dict_sorted(d, precision):\n",
    "    \"\"\"print a dictionnary sorted by it's keys\n",
    "    argument 'precision': gives number of desired leading zeros\n",
    "    \"\"\"\n",
    "    print(\"Weight of each node :\")\n",
    "    for k, v in sorted(d.items()): \n",
    "        print(\"Node\",str(k).zfill(precision),\"has score\", v)\n",
    "\n",
    "#Surfer\n",
    "def surfer(G, jumps):\n",
    "    \"\"\"Surfs through an networkX graph\"\"\"\n",
    "    nodes_list = G.nodes()\n",
    "    nodes_and_weight = dict(zip(G.nodes(), [0]*G.number_of_nodes()))\n",
    "    seed = random.sample(nodes_list, 1).pop()\n",
    "    current = seed\n",
    "    i = 0\n",
    "    while i < jumps:\n",
    "        \n",
    "        nodes_and_weight[current] += 1\n",
    "        i+= 1\n",
    "        possible_nodes = G.edges(current)\n",
    "        if len(possible_nodes) >= 1: #check for dead end\n",
    "            current = random.sample(possible_nodes,1).pop()[1]\n",
    "        else:\n",
    "            print(\"Reached a dead end after\",i-1,\"jumps and\",i,\"visited pages. No links in this page\")\n",
    "            break\n",
    "        \n",
    "    #return normalized version\n",
    "    nodes_and_weight.update((k, v/i) for k,v in nodes_and_weight.items())\n",
    "    return nodes_and_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of components graph\n",
    "We see below that not all components are connected (the network is not one giant component). Thus, entering at one node traps us in the connected component and excludes us from different component(s). This behaviour is to be avoided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of each node :\n",
      "Node 0 has score 0.0\n",
      "Node 1 has score 0.0\n",
      "Node 2 has score 0.0\n",
      "Node 3 has score 0.0\n",
      "Node 4 has score 0.28\n",
      "Node 5 has score 0.15\n",
      "Node 6 has score 0.29\n",
      "Node 7 has score 0.28\n"
     ]
    }
   ],
   "source": [
    "surf1 = surfer(G1, jumps)\n",
    "print_dict_sorted(surf1, 1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of absorbing graph\n",
    "The result here is better seen when launching the code multiple times.\n",
    "We quickly see there is a dangling node (node with no outgoing edges). This denotes an absorbing behaviour, meaning once this node is reached we can't keep crawling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached a dead end after 1 jumps and 2 visited pages. No links in this page\n",
      "Weight of each node :\n",
      "Node 0 has score 0.0\n",
      "Node 1 has score 0.5\n",
      "Node 2 has score 0.0\n",
      "Node 3 has score 0.0\n",
      "Node 4 has score 0.5\n"
     ]
    }
   ],
   "source": [
    "surf2 = surfer(G2, jumps)\n",
    "print_dict_sorted(surf2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modified_surfer(G, jumps, dang_fac):\n",
    "    \"\"\"Surfs through an networkX graph\"\"\"\n",
    "    nodes_list = G.nodes()\n",
    "    nodes_and_weight = dict(zip(G.nodes(), [0]*G.number_of_nodes())) #creates dict of node ID and it's score (0)\n",
    "    seed = random.sample(nodes_list, 1).pop()\n",
    "    current = seed\n",
    "    i = 0\n",
    "    while i < jumps:\n",
    "        \n",
    "        nodes_and_weight[current] += 1\n",
    "        possible_nodes = G.edges(current)\n",
    "        if len(possible_nodes) == 0 or random.randrange(0, 1) < dang_fac: \n",
    "            current = random.sample(nodes_list, 1).pop() #take one node at random\n",
    "        else:\n",
    "            current = random.sample(possible_nodes,1).pop()[1] #pick one in linked nodes\n",
    "        i += 1\n",
    "        \n",
    "    #return normalized version\n",
    "    nodes_and_weight.update((k, v/i) for k,v in nodes_and_weight.items())\n",
    "    return nodes_and_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of components graph with modified surfer\n",
    "The below result seems much better, as we now visited all components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of each node :\n",
      "Node 0 has score 0.13\n",
      "Node 1 has score 0.15\n",
      "Node 2 has score 0.14\n",
      "Node 3 has score 0.08\n",
      "Node 4 has score 0.11\n",
      "Node 5 has score 0.1\n",
      "Node 6 has score 0.18\n",
      "Node 7 has score 0.11\n"
     ]
    }
   ],
   "source": [
    "surf1 = modified_surfer(G1, jumps, dangling_fac)\n",
    "print_dict_sorted(surf1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of absorbing graph with modified surfer\n",
    "Our surfer does not halt anymore when reaching a dangling node, which is the correct behaviour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of each node :\n",
      "Node 0 has score 0.21\n",
      "Node 1 has score 0.23\n",
      "Node 2 has score 0.16\n",
      "Node 3 has score 0.14\n",
      "Node 4 has score 0.26\n"
     ]
    }
   ],
   "source": [
    "surf2 = modified_surfer(G2, jumps, dangling_fac)\n",
    "print_dict_sorted(surf2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General observations\n",
    "We"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.2 Power Iteration Method\n",
    "\n",
    "#### Exercise 2.14: Power Iteration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "theta = 0.85\n",
    "\n",
    "def google_matrix(graph):\n",
    "    #Compute the google matrix for the given graph\n",
    "    N = graph.number_of_nodes()\n",
    "    w = np.zeros(N) #dangling indicator\n",
    "    H = np.zeros((N, N))\n",
    "\n",
    "    for node in graph.nodes(): #analyse every node iteratively\n",
    "        edges = (graph.edges(node)) #type : edges = list of connected nodes\n",
    "        if(len(edges) == 0): #no outgoing egde <-> dangling node\n",
    "            w[node] = 1\n",
    "        else :\n",
    "            edges_indices = np.array([x[1] for x in edges], dtype=int)  \n",
    "            H[node][edges_indices] = 1/len(edges)\n",
    "    H2 = H + ((w) * np.ones((N,1)).T)/N\n",
    "    G = theta*H2 + (1-theta)*np.ones((N, N))/N\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = google_matrix(Gwiki)\n",
    "N = Gwiki.number_of_nodes()\n",
    "pivec = np.ones(N)/N #original pi\n",
    "for i in range(10000): #long operation, decrease for faster result\n",
    "    pivec = pivec @ G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/wikipedia_titles.tsv', newline='\\n') as datafile:\n",
    "    fin = datafile.read().splitlines(True)[1:]\n",
    "    reader = csv.reader(fin, delimiter='\\t')\n",
    "dictionnary = dict((int(row[0]), row[1]) for row in reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 max elements are :\n",
      "# 1 : United States with score 0.00524242749513\n",
      "# 2 : United Kingdom with score 0.00362983460401\n",
      "# 3 : France with score 0.00350494836571\n",
      "# 4 : Europe with score 0.00314154855823\n",
      "# 5 : Germany with score 0.00277779516965\n",
      "# 6 : England with score 0.0026988678281\n",
      "# 7 : World War II with score 0.00260878825491\n",
      "# 8 : Latin with score 0.00252908551565\n",
      "# 9 : India with score 0.00251866054902\n",
      "# 10 : English language with score 0.00236892006868\n"
     ]
    }
   ],
   "source": [
    "desired_max = 10\n",
    "# np.argpartition is an efficient way to get top N values but returns them unsorted.\n",
    "max_indices = np.argpartition(pivec, -desired_max)[-desired_max:]\n",
    "value_to_index = map(lambda x : (pivec[x], x), max_indices) #create tuple (rank, id)\n",
    "\n",
    "#Sort only the top N values by their rank (x[0])\n",
    "sorted_indices = sorted(value_to_index, key= lambda x:x[0], reverse=True)\n",
    "\n",
    "print(\"The\",desired_max,\"max elements are :\")\n",
    "j = 1\n",
    "for i in sorted_indices:    \n",
    "    print(\"#\",j,\":\",dictionnary[i[1]],\"with score\",i[0])\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.3 Gaming the system *(Bonus)*\n",
    "\n",
    "#### Exercise 2.15 *(Bonus)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy :\n",
    "The PageRanks will get a higher score when being pointed to from popular pages. So we select the 300 most popular pages, and add a link from them to our goal page. As we have a high chance to get to the popular pages, and each of them point to our page, we will have a better chance to get visited (thus a better rank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of 'History of mathematics' before : 6.92005788086e-05\n",
      "Score of 'History of mathematics' after : 0.00328181512156\n"
     ]
    }
   ],
   "source": [
    "#find id of boost node\n",
    "id_history = list(dictionnary.keys())[list(dictionnary.values()).index('History of mathematics')]\n",
    "desired_max = 300\n",
    "popular_nodes = np.argpartition(pivec, -desired_max)[-desired_max:]\n",
    "\n",
    "print(\"Score of 'History of mathematics' before :\",pivec[id_history])\n",
    "\n",
    "\n",
    "#Tuples (booster, popular_nodes). Represent links to be added.\n",
    "new_links = zip(popular_nodes, [id_history]*desired_max)\n",
    "\n",
    "#read graph once more. somehow, copy() does not work correctly. \n",
    "#We create a new graph to avoid \"polluting\" the original one. \n",
    "Gwiki2 = nx.read_adjlist('../data/wikipedia.graph', create_using=nx.DiGraph(), nodetype=int)\n",
    "\n",
    "#add our edges\n",
    "Gwiki2.add_edges_from(new_links)\n",
    "\n",
    "#recompute google matrix, and scores\n",
    "G2 = google_matrix(Gwiki2)\n",
    "pivec2 = np.ones(N)/N #original pi\n",
    "for i in range(10000): #long operation\n",
    "    pivec2 = pivec2 @ G2\n",
    "    \n",
    "print(\"Score of 'History of mathematics' after :\",pivec2[id_history])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
